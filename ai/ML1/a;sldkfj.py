import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import os

class LSTMSequencePredictor:
    """
    LSTM Neural Network for Cryptocurrency Price Sequence Prediction
    """
    
    def __init__(self, sequence_length=60, n_features=1):
        self.sequence_length = sequence_length
        self.n_features = n_features
        self.model = None
        self.scaler = MinMaxScaler()
        self.history = None
        
    def load_and_prepare_data(self, csv_path=None):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        """
        if csv_path is None:
            # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º BTC/USDT
            csv_path = os.path.join("..", "..", "data", "binance", "BTCUSDT", "1d", "2018_01_01-now.csv")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = pd.read_csv(csv_path)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ü–µ–Ω—É –∑–∞–∫—Ä—ã—Ç–∏—è
        data = df[['close']].values
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        scaled_data = self.scaler.fit_transform(data)
        
        return scaled_data
    
    def create_sequences(self, data, train_size=0.8):
        """
        –°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LSTM
        """
        X, y = [], []
        
        for i in range(self.sequence_length, len(data)):
            X.append(data[i-self.sequence_length:i])
            y.append(data[i])
        
        X, y = np.array(X), np.array(y)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        split_idx = int(len(X) * train_size)
        
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        return X_train, X_test, y_train, y_test
    
    def build_model(self, lstm_units=[50, 50], dropout_rate=0.2):
        """
        –°–æ–∑–¥–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É LSTM –º–æ–¥–µ–ª–∏
        """
        self.model = Sequential()
        
        # –ü–µ—Ä–≤—ã–π LSTM —Å–ª–æ–π
        self.model.add(LSTM(
            units=lstm_units[0],
            return_sequences=True if len(lstm_units) > 1 else False,
            input_shape=(self.sequence_length, self.n_features)
        ))
        self.model.add(Dropout(dropout_rate))
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ LSTM —Å–ª–æ–∏
        for i, units in enumerate(lstm_units[1:], 1):
            return_seq = i < len(lstm_units) - 1
            self.model.add(LSTM(units=units, return_sequences=return_seq))
            self.model.add(Dropout(dropout_rate))
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        self.model.add(Dense(units=1))
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
        self.model.compile(
            optimizer='adam',
            loss='mean_squared_error',
            metrics=['mae']
        )
        
        return self.model
    
    def train(self, X_train, y_train, X_val=None, y_val=None, 
              epochs=100, batch_size=32, verbose=1):
        """
        –û–±—É—á–∞–µ—Ç LSTM –º–æ–¥–µ–ª—å
        """
        if self.model is None:
            self.build_model()
        
        # –ö–æ–ª–±—ç–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss' if X_val is not None else 'loss',
                patience=10,
                restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss' if X_val is not None else 'loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7
            )
        ]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        validation_data = (X_val, y_val) if X_val is not None else None
        
        # –û–±—É—á–µ–Ω–∏–µ
        self.history = self.model.fit(
            X_train, y_train,
            validation_data=validation_data,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=verbose
        )
        
        return self.history
    
    def predict(self, X):
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ train() —Å–Ω–∞—á–∞–ª–∞.")
        
        predictions = self.model.predict(X)
        # –û–±—Ä–∞—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        predictions = self.scaler.inverse_transform(predictions)
        
        return predictions
    
    def evaluate(self, X_test, y_test):
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
        """
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = self.model.predict(X_test)
        
        # –û–±—Ä–∞—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        y_test_scaled = self.scaler.inverse_transform(y_test)
        predictions_scaled = self.scaler.inverse_transform(predictions)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(y_test_scaled, predictions_scaled)
        mae = mean_absolute_error(y_test_scaled, predictions_scaled)
        rmse = np.sqrt(mse)
        
        print(f"MSE: {mse:.2f}")
        print(f"MAE: {mae:.2f}")
        print(f"RMSE: {rmse:.2f}")
        
        return {
            'mse': mse,
            'mae': mae, 
            'rmse': rmse,
            'predictions': predictions_scaled,
            'actual': y_test_scaled
        }
    
    def plot_training_history(self):
        """
        –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
        """
        if self.history is None:
            print("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞.")
            return
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Loss
        ax1.plot(self.history.history['loss'], label='Training Loss')
        if 'val_loss' in self.history.history:
            ax1.plot(self.history.history['val_loss'], label='Validation Loss')
        ax1.set_title('Model Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        
        # MAE
        ax2.plot(self.history.history['mae'], label='Training MAE')
        if 'val_mae' in self.history.history:
            ax2.plot(self.history.history['val_mae'], label='Validation MAE')
        ax2.set_title('Model MAE')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('MAE')
        ax2.legend()
        
        plt.tight_layout()
        plt.show()
    
    def plot_predictions(self, y_actual, y_pred, start_idx=0, end_idx=200):
        """
        –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        """
        plt.figure(figsize=(15, 6))
        
        x_range = range(start_idx, min(end_idx, len(y_actual)))
        
        plt.plot(x_range, y_actual[start_idx:end_idx], 
                label='Actual Price', linewidth=2, alpha=0.8)
        plt.plot(x_range, y_pred[start_idx:end_idx], 
                label='Predicted Price', linewidth=2, alpha=0.8)
        
        plt.title('BTC Price Prediction vs Actual')
        plt.xlabel('Time Steps')
        plt.ylabel('Price (USD)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã LSTM –º–æ–¥–µ–ª–∏
    """
    print("üöÄ –ó–∞–ø—É—Å–∫ LSTM –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã BTC...")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–æ–¥–µ–ª–∏
    lstm_predictor = LSTMSequencePredictor(sequence_length=60)
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        scaled_data = lstm_predictor.load_and_prepare_data()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π...")
        X_train, X_test, y_train, y_test = lstm_predictor.create_sequences(scaled_data)
        
        print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
        print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape}")
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        print("üèóÔ∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ LSTM –º–æ–¥–µ–ª–∏...")
        lstm_predictor.build_model(lstm_units=[50, 50, 25])
        print(lstm_predictor.model.summary())
        
        # –û–±—É—á–µ–Ω–∏–µ
        print("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        lstm_predictor.train(
            X_train, y_train,
            X_val=X_test, y_val=y_test,
            epochs=50,
            batch_size=32
        )
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        print("üìà –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")
        results = lstm_predictor.evaluate(X_test, y_test)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        print("üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
        lstm_predictor.plot_training_history()
        lstm_predictor.plot_predictions(
            results['actual'], 
            results['predictions'],
            end_idx=100
        )
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏.")

if __name__ == "__main__":
    main()