import os
import numpy as np
import torch
from stable_baselines3 import DQN
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import BaseCallback
from .base_agent import BaseAgent

class DQNAgent(BaseAgent):
    def __init__(self, config):
        super().__init__(config)
        self.model = None
        self.vec_env = None
        self.device = self._get_device()
        
    def _get_device(self):
        """–í–∏–∑–Ω–∞—á–∏—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω–∏–π –ø—Ä–∏—Å—Ç—Ä—ñ–π (GPU –∞–±–æ CPU)."""
        if torch.cuda.is_available():
            device = "cuda"
            gpu_name = torch.cuda.get_device_name(0)
            print(f"üöÄ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è GPU: {gpu_name}")
            print(f"üíæ –î–æ—Å—Ç—É–ø–Ω–∞ –≤—ñ–¥–µ–æ–ø–∞–º'—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            device = "cpu"
            print("üîß GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU")
        return device
        
    def create_model(self, env, model_config=None):
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ –º–æ–¥–µ–ª—å DQN."""
        # –û–±–æ—Ä–∞—á–∏–≤–∞—î–º–æ —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ
        self.vec_env = DummyVecEnv([lambda: env])
        
        # –°—Ç–∞–±—ñ–ª—å–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –≤–∏—Å–æ–∫–∏—Ö –≤—Ç—Ä–∞—Ç
        default_config = {
            'learning_rate': 1e-5,  # –î—É–∂–µ –Ω–∏–∑—å–∫–∏–π learning rate
            'buffer_size': 50000,  # –ú–µ–Ω—à–∏–π –±—É—Ñ–µ—Ä –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—é
            'learning_starts': 5000,  # –†–∞–Ω—ñ—à–µ –ø–æ—á–∞—Ç–æ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è
            'batch_size': 32,  # –ú–µ–Ω—à–∏–π batch size –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ
            'tau': 0.001,  # –î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è target network
            'gamma': 0.99,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –¥–∏—Å–∫–æ–Ω—Ç —Ñ–∞–∫—Ç–æ—Ä
            'train_freq': 8,  # –†—ñ–¥—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ
            'gradient_steps': 1,  # –û–¥–∏–Ω –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π –∫—Ä–æ–∫
            'target_update_interval': 2000,  # –†—ñ–¥—à–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è target network
            'exploration_fraction': 0.5,  # –ë—ñ–ª—å—à–µ exploration
            'exploration_initial_eps': 0.9,  # –ú–µ–Ω—à–∏–π –ø–æ—á–∞—Ç–∫–æ–≤–∏–π epsilon
            'exploration_final_eps': 0.01,  # –î—É–∂–µ –Ω–∏–∑—å–∫–∏–π –∫—ñ–Ω—Ü–µ–≤–∏–π epsilon
            'max_grad_norm': 1.0,  # –ñ–æ—Ä—Å—Ç–∫–∏–π –∫–ª–∏–ø—ñ–Ω–≥ –≥—Ä–∞–¥—ñ—î–Ω—Ç—ñ–≤
            'verbose': 1,
            # –°—Ç–∞–±—ñ–ª—å–Ω–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ
            'policy_kwargs': {
                'net_arch': [64, 64],  # –ú–µ–Ω—à–∞ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ
                'activation_fn': torch.nn.Tanh,  # Tanh –¥–ª—è –æ–±–º–µ–∂–µ–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å
                'normalize_images': False
            }
        }
        
        if model_config:
            default_config.update(model_config)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –º–æ–¥–µ–ª—å DQN
        self.model = DQN(
            "MlpPolicy",
            self.vec_env,
            device=self.device,
            **default_config
        )
        
        print(f"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–∞ DQN –º–æ–¥–µ–ª—å:")
        print(f"   Learning rate: {default_config['learning_rate']}")
        print(f"   Network architecture: {default_config['policy_kwargs']['net_arch']}")
        print(f"   Buffer size: {default_config['buffer_size']}")
        print(f"   Exploration: {default_config['exploration_initial_eps']} ‚Üí {default_config['exploration_final_eps']}")
        
        return self.model
    
    def train(self, total_timesteps=100000, callback=None):
        """–ù–∞–≤—á–∏—Ç–∏ –∞–≥–µ–Ω—Ç–∞."""
        if not self.model:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–∞. –í–∏–∫–ª–∏—á—Ç–µ create_model() —Å–ø–æ—á–∞—Ç–∫—É.")
        
        self.model.learn(
            total_timesteps=total_timesteps,
            callback=callback
        )
        
        return self.model
    
    def act(self, state):
        """–û–±—Ä–∞—Ç–∏ –¥—ñ—é."""
        if not self.model:
            return np.array([0.0])
        
        action, _ = self.model.predict(state, deterministic=True)
        return action
    
    def save(self, path):
        """–ó–±–µ—Ä–µ–≥—Ç–∏ –º–æ–¥–µ–ª—å."""
        if self.model:
            self.model.save(path)
    
    def load(self, path, env=None):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å."""
        if env:
            self.vec_env = DummyVecEnv([lambda: env])
        
        self.model = DQN.load(path, env=self.vec_env)
        return self.model