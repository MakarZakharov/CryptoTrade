# Professional PPO Configuration for Crypto Trading
# BTCUSDT 15m timeframe - Optimized for financial markets

# Environment Configuration
environment:
  symbols: ['BTCUSDT']
  timeframe: '15m'
  exchange: 'binance'
  initial_balance: 100000.0
  commission_rate: 0.001
  min_trade_size: 10.0
  lookback_window: 50
  max_steps: 2000
  
  # Market Realism Features
  enable_slippage: true
  enable_market_impact: true
  enable_liquidity_modeling: true
  enable_order_book: true
  enable_partial_fills: true
  base_slippage: 0.0005
  max_order_book_levels: 20
  
  # Risk Management
  max_position_size: 1
  stop_loss_pct: 0.05
  take_profit_pct: 0.03

# Data Configuration  
data:
  train_start: '2018-01-01'
  train_end: '2022-12-31'
  test_start: '2023-01-01' 
  test_end: '2024-12-31'
  validation_split: 0.15  # 15% of training data for validation

# PPO Algorithm Configuration
algorithm:
  name: 'PPO'
  learning_rate: 3e-4
  gamma: 0.99
  gae_lambda: 0.95
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  clip_range: 0.2
  clip_range_vf: null
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: null
  use_sde: false
  sde_sample_freq: -1

# Network Architecture
network:
  policy_type: 'MlpPolicy'
  net_arch:
    pi: [256, 256]  # Policy network layers
    vf: [256, 256]  # Value function network layers
  activation_fn: 'Tanh'
  normalize_features: true
  squash_output: false

# Training Configuration
training:
  total_timesteps: 1000000  # 1M steps minimum requirement
  eval_freq: 10000
  n_eval_episodes: 5
  save_freq: 50000
  seed: 42
  verbose: 1
  
  # Early stopping
  patience: 50  # Stop if no improvement for 50 evaluations
  min_improvement: 0.01  # Minimum improvement threshold

# Logging Configuration
logging:
  use_wandb: false  # Set to false to use TensorBoard
  wandb_project: 'crypto-drl-trading'
  wandb_entity: null  # Your W&B username
  run_name: null  # Auto-generated if null
  
  tensorboard_log: './logs/tensorboard'
  log_interval: 100
  
  # Metrics to track
  track_metrics:
    - 'cumulative_reward'
    - 'episode_length' 
    - 'portfolio_value'
    - 'sharpe_ratio'
    - 'max_drawdown'
    - 'win_rate'
    - 'total_trades'
    - 'profit_factor'
    - 'policy_loss'
    - 'value_loss'
    - 'entropy_loss'

# Evaluation Configuration
evaluation:
  metrics:
    - 'total_return'
    - 'sharpe_ratio'
    - 'max_drawdown'
    - 'calmar_ratio'
    - 'win_rate'
    - 'profit_factor'
    - 'avg_trade_duration'
    - 'total_trades'
    - 'volatility'
    
  # Benchmark comparisons
  benchmarks:
    - 'buy_and_hold'
    - 'random_trading'
    - 'simple_ma_crossover'
    
  # Visualization
  generate_plots: true
  plot_types:
    - 'equity_curve'
    - 'drawdown_curve'
    - 'action_distribution'
    - 'reward_per_episode'
    - 'trades_timeline'

# Hardware Configuration
hardware:
  device: 'auto'  # 'cuda', 'cpu', or 'auto'
  n_envs: 1  # Number of parallel environments
  use_multiprocessing: false

# Reproducibility
reproducibility:
  deterministic_pytorch: true
  benchmark_pytorch: false
  
# Paths
paths:
  models_dir: './models'
  logs_dir: './logs'
  data_dir: '../../../data/binance'
  results_dir: './results'
  checkpoints_dir: './checkpoints'