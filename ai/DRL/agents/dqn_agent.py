import os
import numpy as np
import torch
from stable_baselines3 import DQN
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import BaseCallback
from .base_agent import BaseAgent

class DQNAgent(BaseAgent):
    def __init__(self, config):
        super().__init__(config)
        self.model = None
        self.vec_env = None
        self.device = self._get_device()
        
    def _get_device(self):
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU –∏–ª–∏ CPU)."""
        if torch.cuda.is_available():
            device = "cuda"
            gpu_name = torch.cuda.get_device_name(0)
            print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {gpu_name}")
            print(f"üíæ –î–æ—Å—Ç—É–ø–Ω–∞—è –≤–∏–¥–µ–æ–ø–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            device = "cpu"
            print("üîß GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
        return device
        
    def create_model(self, env, model_config=None):
        """–°–æ–∑–¥–∞—Ç—å –º–æ–¥–µ–ª—å DQN."""
        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º —Å—Ä–µ–¥—É
        self.vec_env = DummyVecEnv([lambda: env])
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        default_config = {
            'learning_rate': 1e-4,
            'buffer_size': 100000,
            'learning_starts': 1000,
            'batch_size': 32,
            'gamma': 0.99,
            'train_freq': 4,
            'gradient_steps': 1,
            'target_update_interval': 1000,
            'exploration_fraction': 0.1,
            'exploration_initial_eps': 1.0,
            'exploration_final_eps': 0.05,
            'verbose': 1
        }
        
        if model_config:
            default_config.update(model_config)
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å DQN
        self.model = DQN(
            "MlpPolicy",
            self.vec_env,
            device=self.device,
            **default_config
        )
        
        return self.model
    
    def train(self, total_timesteps=100000, callback=None):
        """–û–±—É—á–∏—Ç—å –∞–≥–µ–Ω—Ç–∞."""
        if not self.model:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ create_model() —Å–Ω–∞—á–∞–ª–∞.")
        
        self.model.learn(
            total_timesteps=total_timesteps,
            callback=callback
        )
        
        return self.model
    
    def act(self, state):
        """–í—ã–±—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ."""
        if not self.model:
            return np.array([0.0])
        
        action, _ = self.model.predict(state, deterministic=True)
        return action
    
    def save(self, path):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å."""
        if self.model:
            self.model.save(path)
    
    def load(self, path, env=None):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å."""
        if env:
            self.vec_env = DummyVecEnv([lambda: env])
        
        self.model = DQN.load(path, env=self.vec_env)
        return self.model 