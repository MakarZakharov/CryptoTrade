# Concurrent Distributed Training System

Эта система позволяет нескольким людям одновременно тренировать одну модель без блокировок.

## Ключевые возможности

1. **Параллельная тренировка**: Несколько участников могут тренировать одновременно
2. **Автоматическое сохранение**: Прогресс сохраняется автоматически
3. **Возобновление тренировки**: Можно остановить и продолжить в любой момент
4. **Обмен опытом**: Участники делятся опытом для ускорения обучения
5. **Федеративное усреднение**: Модели участников автоматически объединяются

## Быстрый старт

### Первый участник:
```bash
python CryptoTrade/ai/ReinforcementLearning/train_concurrent.py --episodes 100
```

### Другие участники (одновременно):
```bash
# Участник 2
python train_concurrent.py --episodes 100 --participant-id "user2"

# Участник 3
python train_concurrent.py --episodes 100 --participant-id "user3"
```

## Как это работает

### 1. Параллельная тренировка
- Каждый участник тренирует свою копию модели
- Нет блокировок - все работают одновременно
- Автоматическая синхронизация каждые 10 эпизодов

### 2. Обмен опытом
- Участники сохраняют свой опыт (наблюдения, действия, награды)
- Другие участники используют этот опыт для обучения
- Ускоряет обучение за счет разнообразия данных

### 3. Федеративное усреднение
- Модели участников периодически усредняются
- Лучшие веса распространяются между всеми
- Предотвращает переобучение на локальных данных

### 4. Автосохранение
- Прогресс сохраняется каждые 50 эпизодов
- Модели сохраняются каждые 10 эпизодов
- Лучшая модель сохраняется отдельно

## Команды и параметры

### Основные параметры:
- `--episodes N` - Количество эпизодов для тренировки (по умолчанию: 100)
- `--total-episodes N` - Общая цель эпизодов (по умолчанию: 1000)
- `--participant-id NAME` - Уникальный ID участника (автогенерация если не указан)
- `--sync-interval N` - Эпизоды между синхронизациями (по умолчанию: 10)
- `--shared-dir DIR` - Директория для общих файлов (по умолчанию: concurrent_models)

### Примеры использования:

```bash
# Тренировать 200 эпизодов с именем участника
python train_concurrent.py --episodes 200 --participant-id "Макар"

# Тренировать с конкретными данными
python train_concurrent.py --data path/to/data.csv --episodes 100

# Изменить интервал синхронизации
python train_concurrent.py --sync-interval 5 --episodes 100

# Установить общую цель в 5000 эпизодов
python train_concurrent.py --total-episodes 5000 --episodes 100
```

## Структура файлов

```
concurrent_models/
├── models/              # Сохраненные модели
│   ├── best_model.pth   # Лучшая модель
│   └── model_*.pth      # Модели участников
├── experiences/         # Общий опыт
│   └── exp_*.npz       # Файлы опыта
└── state/              # Состояние тренировки
    └── global_state.json
```

## Возобновление тренировки

### Проверка статуса:
```bash
python train_concurrent.py --episodes 0
```
Покажет текущий прогресс без тренировки.

### Продолжение тренировки:
```bash
python train_concurrent.py --episodes 100
```
Автоматически продолжит с последнего сохранения.

### После завершения целевых эпизодов:
```bash
python train_concurrent.py --total-episodes 2000 --episodes 100
```
Увеличит цель и продолжит тренировку.

## Мониторинг прогресса

### В реальном времени:
Каждый участник видит:
- Локальный прогресс
- Глобальный прогресс
- Лучшую награду
- Количество активных участников

### Файл состояния:
```bash
cat concurrent_models/state/global_state.json
```

Показывает:
- Общее количество эпизодов
- Вклад каждого участника
- Историю моделей
- Лучшую награду

## Преимущества

1. **Скорость**: Линейное ускорение с количеством участников
2. **Надежность**: Отказ одного участника не влияет на других
3. **Гибкость**: Участники могут присоединяться и уходить в любое время
4. **Качество**: Обмен опытом улучшает обобщение модели

## Рекомендации

1. **Координация**: Договоритесь о данных и параметрах
2. **Регулярность**: Тренируйте регулярно для лучших результатов
3. **Мощность**: Используйте GPU если доступен (`--device cuda`)
4. **Сеть**: Убедитесь что папка concurrent_models доступна всем

## Решение проблем

### "No such file or directory"
Убедитесь что папка concurrent_models существует и доступна.

### Медленная синхронизация
Уменьшите частоту: `--sync-interval 20`

### Нехватка памяти
Уменьшите количество эпизодов: `--episodes 50`

## Сравнение с последовательной системой

| Функция | Последовательная | Параллельная |
|---------|------------------|--------------|
| Одновременные участники | ❌ 1 | ✅ Неограниченно |
| Скорость обучения | Обычная | Линейно быстрее |
| Обмен опытом | ❌ | ✅ |
| Требует координации | ✅ | ❌ |
| Сложность | Простая | Средняя |